{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNrzTpQKoXO33GmnaAKoDhd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Onectwo/llm-notebooks/blob/main/Mistral_with_simple_k_retrieval_with_langchain_hf.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install chromadb\n",
        "!pip install langchain\n",
        "!pip install pypdf\n",
        "!pip install sentencepiece\n",
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install git+https://github.com/UKPLab/sentence-transformers.git\n",
        "!pip install git+https://github.com/Muennighoff/sentence-transformers.git@sgpt_poolings_specb\n",
        "!pip install --upgrade git+https://github.com/UKPLab/sentence-transformers.git\n",
        "!pip install -U sentence-transformers"
      ],
      "metadata": {
        "id": "cwDGIxIrQxXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-n-tWoKhQoMS"
      },
      "outputs": [],
      "source": [
        "# load required library\n",
        "import os\n",
        "import torch\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "load_in_4bit=True,\n",
        "bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model_kwargs = {'device': 'cuda'}\n",
        "embeddings = HuggingFaceEmbeddings(model_kwargs=model_kwargs)\n",
        "# HuggingFaceH4/zephyr-7b-beta\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.2\", device_map='auto', quantization_config=quantization_config)\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=400)\n",
        "llm = HuggingFacePipeline(pipeline=pipe)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the PDF file\n",
        "pdf_link = \"./sample_data/5985101 Prüfplan S1 Spindelmotoren.pdf\"\n",
        "loader = PyPDFLoader(pdf_link, extract_images=False)\n",
        "pages = loader.load_and_split()\n",
        "\n",
        "\n",
        "# Split data into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "   chunk_size = 4096,\n",
        "   chunk_overlap  = 40,\n",
        "   length_function = len,\n",
        "   add_start_index = True,\n",
        ")\n",
        "chunks = text_splitter.split_documents(pages)"
      ],
      "metadata": {
        "id": "JRUuCYRUSdsk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store data into database\n",
        "db=Chroma.from_documents(chunks,embedding=embeddings,persist_directory=\"test_index\")\n",
        "db.persist()"
      ],
      "metadata": {
        "id": "kGQDj3cXS3Ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the database\n",
        "vectordb = Chroma(persist_directory=\"test_index\", embedding_function = embeddings)\n",
        "\n",
        "# Load the retriver\n",
        "retriever = vectordb.as_retriever(search_kwargs = {\"k\" : 3})\n",
        "qna_prompt_template=\"\"\"### [INST]Instruction: Bitte nur auf Deutsch Antworten!  Ihnen werden eine Frage und zugehörige Daten zur Verfügung gestellt. Ihre Aufgabe ist es, die genaueste Antworten auf die Frage  anhand der gegebenen Daten zu finden. Wenn die Daten die Antwort auf die Frage nicht enthalten, müssen Sie \"Nicht genug Informationen\" zurückgeben.\n",
        "{context}\n",
        "\n",
        "### Question: {question} [/INST]\"\"\"\n",
        "\n",
        "PROMPT = PromptTemplate(\n",
        "   template=qna_prompt_template, input_variables=[\"context\", \"question\"]\n",
        ")\n",
        "chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=PROMPT)"
      ],
      "metadata": {
        "id": "ETuCsCu9S48J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A utility function for answer generation\n",
        "def ask(question):\n",
        "   context = retriever.get_relevant_documents(question)\n",
        "   print(context)\n",
        "\n",
        "   answer = (chain({\"input_documents\": context, \"question\": question}, return_only_outputs=True))['output_text']\n",
        "   return answer"
      ],
      "metadata": {
        "id": "QsDhJrKLS7X2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Take the user input and call the function to generate output\n",
        "user_question = input(\"User: \")\n",
        "answer = ask(user_question)\n",
        "print(\"Answer:\", answer)\n"
      ],
      "metadata": {
        "id": "dVlqp4l_S93o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}